{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "### test the quality of the gold stanards of the Ad prompt"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from nltk import tokenize\n",
    "import numpy as np\n",
    "from sklearn.cluster import MiniBatchKMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.metrics import silhouette_samples\n",
    "import pandas as pd\n",
    "from sentence_transformers import SentenceTransformer,util\n",
    "import re\n",
    "\n",
    "\n",
    "##############################################################################################################`\n",
    "\n",
    "\n",
    "model = SentenceTransformer('all-mpnet-base-v2', device=\"cuda\")\n",
    "\n",
    "\n",
    "##############################################################################################################\n",
    "\n",
    "\n",
    "listStructureWords =  []\n",
    "\n",
    "dfSrtucturingWords = pd.read_excel(\"../structureWords.xlsx\")\n",
    "\n",
    "listStructureWords = dfSrtucturingWords.iloc[:,0].tolist()\n",
    "\n",
    "regex = r\"\\b(?:{})\\b\".format(\"|\".join(listStructureWords))\n",
    "sentences = []\n",
    "\n",
    "df_fileName = pd.DataFrame({})\n",
    "\n",
    "for filename in os.listdir(r\"D:\\UDE\\6th Semester\\MEMS\\MEWS Data\\MEWS_Essays\\MEWS_Essays\\Essays_all\\TelevisonMergedT1+T2\"):\n",
    "   with open(os.path.join(r\"D:\\UDE\\6th Semester\\MEMS\\MEWS Data\\MEWS_Essays\\MEWS_Essays\\Essays_all\\TelevisonMergedT1+T2\", filename)) as f:\n",
    "       text = f.read()\n",
    "       text = text.replace(\"ï»¿\",\"\")\n",
    "       sents = re.split(regex, text)\n",
    "       sents = tokenize.sent_tokenize(text)\n",
    "       for s in sents:\n",
    "           sentses = tokenize.sent_tokenize(s)\n",
    "           if (s.isspace() or len(s) ==0):\n",
    "               continue\n",
    "           s = s.lower()\n",
    "           if (len(s.split()) <5):\n",
    "               continue\n",
    "           for ss in sentses:\n",
    "                 if (len(ss.split()) >5):\n",
    "                     sentences.append(ss)\n",
    "\n",
    "##############################################################################################################\n",
    "\n",
    "corpus_embeddings = model.encode(sentences, show_progress_bar =True, device=\"cuda\")\n",
    "\n",
    "def mbkmeans_clusters(X, k, mb=500, print_silhouette_values=False):\n",
    "    \"\"\"Generate clusters.\n",
    "\n",
    "    Args:\n",
    "        X: Matrix of features.\n",
    "        k: Number of clusters.\n",
    "        mb: Size of mini-batches. Defaults to 500.\n",
    "        print_silhouette_values: Print silhouette values per cluster.\n",
    "\n",
    "    Returns:\n",
    "        Trained clustering model and labels based on X.\n",
    "    \"\"\"\n",
    "    km = MiniBatchKMeans(n_clusters=k, batch_size=mb).fit(X)\n",
    "    print(f\"For n_clusters = {k}\")\n",
    "    print(f\"Silhouette coefficient: {silhouette_score(X, km.labels_):0.2f}\")\n",
    "    print(f\"Inertia:{km.inertia_}\")\n",
    "\n",
    "    if print_silhouette_values:\n",
    "        sample_silhouette_values = silhouette_samples(X, km.labels_)\n",
    "        print(f\"Silhouette values:\")\n",
    "        silhouette_values = []\n",
    "        for i in range(k):\n",
    "            cluster_silhouette_values = sample_silhouette_values[km.labels_ == i]\n",
    "            silhouette_values.append(\n",
    "                (\n",
    "                    i,\n",
    "                    cluster_silhouette_values.shape[0],\n",
    "                    cluster_silhouette_values.mean(),\n",
    "                    cluster_silhouette_values.min(),\n",
    "                    cluster_silhouette_values.max(),\n",
    "                )\n",
    "            )\n",
    "        silhouette_values = sorted(\n",
    "            silhouette_values, key=lambda tup: tup[2], reverse=True\n",
    "        )\n",
    "        for s in silhouette_values:\n",
    "            print(\n",
    "                f\"    Cluster {s[0]}: Size:{s[1]} | Avg:{s[2]:.2f} | Min:{s[3]:.2f} | Max: {s[4]:.2f}\"\n",
    "            )\n",
    "    return km, km.labels_\n",
    "\n",
    "##############################################################################################################\n",
    "\n",
    "\n",
    "k = 19\n",
    "\n",
    "clustering, cluster_labels = mbkmeans_clusters(X=corpus_embeddings, k=k, print_silhouette_values=True)\n",
    "\n",
    "df_clusters = pd.DataFrame({\n",
    "    \"text\": sentences,\n",
    "    \"cluster\": cluster_labels\n",
    "})\n",
    "\n",
    "df_clusters.to_excel(\"TestClusterReference-WithMultiThreshold-AD.xlsx\")\n",
    "\n",
    "##############################################################################################################\n",
    "\n",
    "\n",
    "df_test = pd.DataFrame({})\n",
    "\n",
    "df_ref = pd.read_excel(r\"D:\\USERS-Load\\PycharmProjects\\pythonProject\\CVS Files\\Ads prompt\\01.08.22\\new Gold standards.xlsx\")\n",
    "\n",
    "def_clusters = pd.read_excel(r\"TestClusterReference-WithMultiThreshold-AD.xlsx\")\n",
    "\n",
    "listRef = df_ref['Gold standard']\n",
    "\n",
    "listClusters = def_clusters['cluster']\n",
    "listNewSentences = def_clusters['text']\n",
    "listembReferences = []\n",
    "\n",
    "for ref in listRef:\n",
    "    listembReferences.append(model.encode(ref))\n",
    "\n",
    "allCosinSimiliarityValues = []\n",
    "allCosinSimiliarity = []\n",
    "countMissed =[]\n",
    "thresholds = [0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,0.95]\n",
    "\n",
    "for emb in corpus_embeddings:\n",
    "    listMax = []\n",
    "    for embref in listembReferences:\n",
    "        cos_sim = util.cos_sim(emb, embref)\n",
    "        listMax.append(cos_sim)\n",
    "    index_max = np.argmax(listMax) #this is the right reference cluster\n",
    "    allCosinSimiliarityValues.append(listMax[index_max])\n",
    "    allCosinSimiliarity.append(index_max)\n",
    "\n",
    "for threshold in thresholds:\n",
    "    mm= 0\n",
    "    countMissedNumber = 0\n",
    "    for i in range(0,len(allCosinSimiliarityValues)):\n",
    "        if (allCosinSimiliarityValues[i] <threshold): #threshold to know if this item does not match any of the references!!!\n",
    "            countMissedNumber = countMissedNumber +1\n",
    "            continue\n",
    "    mm = mm+1\n",
    "    countMissed.append(countMissedNumber)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_test = pd.DataFrame({})\n",
    "for i in range(0,len(allCosinSimiliarityValues)):\n",
    "     df_test = df_test.append({\n",
    "        \"ID\" : i,\n",
    "        \"text\": listNewSentences[i],\n",
    "        \"cluster\": listClusters[i],\n",
    "        \"cos Sim\": allCosinSimiliarity[i],\n",
    "        \"similarity value\": allCosinSimiliarityValues[i][0][0]\n",
    "              },ignore_index=True)\n",
    "\n",
    "df_test.to_excel(\"TestClusterReference-WithMultiThreshold-AD - Threshold - 0.5.xlsx\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(countMissed)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "### plotting the results in form of a graph"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# x axis values\n",
    "x = thresholds\n",
    "# corresponding y axis values\n",
    "y = countMissed\n",
    "\n",
    "# plotting the points\n",
    "plt.plot(x, y, color='green', linestyle='dashed', linewidth = 3,\n",
    "         marker='o', markerfacecolor='blue', markersize=12)\n",
    "\n",
    "# setting x and y axis range\n",
    "plt.xlim(0.1,1)\n",
    "plt.ylim(50,70000)\n",
    "\n",
    "# naming the x axis\n",
    "plt.xlabel('x - axis - value of the threshold')\n",
    "# naming the y axis\n",
    "plt.ylabel('y - axis - Number of igonred items')\n",
    "\n",
    "# giving a title to my graph\n",
    "plt.title('Graph between the value of threshold vs number of Igonred items - Ads')\n",
    "\n",
    "# function to show the plot\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}