{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Importing section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "outputs": [],
   "source": [
    "import os\n",
    "import string\n",
    "from nltk import tokenize\n",
    "from gensim.models import Word2Vec\n",
    "from nltk import word_tokenize\n",
    "import numpy as np\n",
    "from sklearn.cluster import MiniBatchKMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.metrics import silhouette_samples\n",
    "import pandas as pd"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Reading the data from the folder and cleaning it."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "outputs": [],
   "source": [
    "sentences = []\n",
    "for filename in os.listdir(r\"D:\\UDE\\6th Semester\\MEMS\\MEWS Data\\MEWS_Essays\\MEWS_Essays\\Essays_all\\TelevisonMergedT1+T2\"):\n",
    "   with open(os.path.join(r\"D:\\UDE\\6th Semester\\MEMS\\MEWS Data\\MEWS_Essays\\MEWS_Essays\\Essays_all\\TelevisonMergedT1+T2\", filename)) as f:\n",
    "       text = f.read()\n",
    "       text = text.replace(\"ï»¿\",\"\")\n",
    "       sents = tokenize.sent_tokenize(text)\n",
    "       for s in sents:\n",
    "           s = s.lower()\n",
    "           s = s.translate(str.maketrans('', '', string.punctuation))\n",
    "           sentences.append(s)\n",
    "\n",
    "tokensSentenceslist = []\n",
    "\n",
    "for s  in sentences:\n",
    "    wordsList = word_tokenize(s)\n",
    "    tokensSentenceslist.append(wordsList)\n",
    "\n",
    "\n",
    "##################### Uncomment below section for testing #########################\n",
    "# print(len(sentences))\n",
    "#\n",
    "# for s in sentences:\n",
    "#      print(\"The sentence is : \")\n",
    "#      print(s)\n",
    "#      print(\"-----------------------End of the sentence -------------\")\n",
    "#\n",
    "# print (sentences)\n",
    "\n",
    "\n",
    "# print (len(tokensSentenceslist))\n",
    "# print (tokensSentenceslist)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38715\n",
      "['advertising in television is becoming more and more clever', 'lots of those ads invade our subconsciousness and try to make us buy the product even if we do not actually need it', 'when it comes to children lots of them dont have enough money to afford these products', 'they dont even understand the concept of money', 'even if they wanted it they can not get the thing they were told they need']\n"
     ]
    }
   ],
   "source": [
    "print (len(sentences))\n",
    "print(sentences[0:5])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Generating the Word2Vec Model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "outputs": [
    {
     "data": {
      "text/plain": "(2373525, 3636460)"
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#model = Word2Vec(tokensSentenceslist, min_count=1)\n",
    "\n",
    "#model = Word2Vec(tokensSentenceslist, vector_size=50, min_count=1, sg=1)\n",
    "#model = Word2Vec(sentences=tokensSentenceslist, vector_size=100, workers=1, seed=42)\n",
    "\n",
    "model = Word2Vec(window=10, min_count=2,workers=6,vector_size=50,seed=42,sg=0)\n",
    "model.build_vocab(tokensSentenceslist, progress_per=1000)\n",
    "model.train(tokensSentenceslist, total_examples=model.corpus_count, epochs=model.epochs)\n",
    "\n",
    "\n",
    "##################### Uncomment below section for testing #########################\n",
    "\n",
    "\n",
    "# print(list(model.wv.index_to_key))\n",
    "# print(len(list(model.wv.index_to_key)))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "outputs": [
    {
     "data": {
      "text/plain": "38715"
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.corpus_count\n",
    "#model.epochs"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model.wv.most_similar(\"television\")\n",
    "model.wv.most_similar(\"argument\")\n",
    "model.wv.similarity(\"tv\",\"against\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "outputs": [
    {
     "data": {
      "text/plain": "-0.1692446"
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def vectorize(list_of_docs, model, strategy):\n",
    "    \"\"\"Generate vectors for list of documents using a Word Emx`bedding.\n",
    "\n",
    "    Args:\n",
    "        list_of_docs: List of documents.\n",
    "        model: Gensim Word Embedding.\n",
    "        strategy: Aggregation strategy (\"average\", or \"min-max\".)\n",
    "\n",
    "    Raises:\n",
    "        ValueError: If the strategy is other than \"average\" or \"min-max\".\n",
    "\n",
    "    Returns:\n",
    "        List of vectors.\n",
    "    \"\"\"\n",
    "    features = []\n",
    "    size_output = model.vector_size\n",
    "    embedding_dict = model\n",
    "\n",
    "    if strategy == \"min-max\":\n",
    "        size_output *= 2\n",
    "\n",
    "    if hasattr(model, \"wv\"):\n",
    "        embedding_dict = model.wv\n",
    "\n",
    "    for tokens in list_of_docs:\n",
    "        zero_vector = np.zeros(size_output)\n",
    "        vectors = []\n",
    "        for token in tokens:\n",
    "            if token in embedding_dict:\n",
    "                try:\n",
    "                    vectors.append(embedding_dict[token])\n",
    "                except KeyError:\n",
    "                    continue\n",
    "        if vectors:\n",
    "            vectors = np.asarray(vectors)\n",
    "            if strategy == \"min-max\":\n",
    "                min_vec = vectors.min(axis=0)\n",
    "                max_vec = vectors.max(axis=0)\n",
    "                features.append(np.concatenate((min_vec, max_vec)))\n",
    "            elif strategy == \"average\":\n",
    "                avg_vec = vectors.mean(axis=0)\n",
    "                features.append(avg_vec)\n",
    "            else:\n",
    "                raise ValueError(f\"Aggregation strategy {strategy} does not exist!\")\n",
    "        else:\n",
    "            features.append(zero_vector)\n",
    "    return features"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "outputs": [],
   "source": [
    "vectorized_docs = vectorize(tokensSentenceslist, model=model, strategy=\"average\")\n",
    " #len(vectorized_docs), len(vectorized_docs[0])\n",
    "# print(model.wv[\"argument\"])\n",
    "# print(\"#######################################################\")\n",
    "# print(vectorized_docs[0])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.0834987   1.0775832  -2.4190793   1.3539352   0.7693121  -0.01766455\n",
      " -0.53748876  2.1623745  -0.5207145   1.694928   -0.2794287   1.4977117\n",
      "  0.3757558  -1.0392004  -1.1415775  -0.37531468  0.23239893  1.364053\n",
      "  1.6795251   0.6714833   0.8824193   1.365521    1.8032991  -0.67293257\n",
      "  1.0104337  -0.03604451  1.0017824  -0.5705173  -0.49769476  1.6430551\n",
      " -1.352539    1.2772088   0.03308525 -2.0387952  -2.4316406  -1.2589905\n",
      "  0.95908076 -2.2138608   0.6789476  -1.0684443   0.03440151  0.9796872\n",
      "  0.9881222  -1.3170159  -2.6712847  -1.2676587   1.5911027  -0.6523292\n",
      " -1.2096913   0.46780825]\n",
      "#######################################################\n",
      "[ 0.09301123  0.02892222  0.02476533  0.29560983 -0.7727718   0.23872662\n",
      "  0.4515218  -0.06879666 -0.03741706 -0.3008877  -0.20542604  0.8528051\n",
      " -0.14720449 -0.2436079  -1.0440915  -0.17934558 -0.21951494 -0.6070896\n",
      "  0.41599515  0.6486483  -0.45739534  0.38212645  0.3662845   0.4625144\n",
      "  0.98150975 -0.35466102  0.38813674 -0.44521755 -1.4364208  -0.07891957\n",
      " -0.056222   -0.19564575  0.38996303 -0.32186234  0.00216475  1.0545774\n",
      " -0.41077358 -0.5827029  -0.9488093   0.06095479 -0.050621   -0.20328291\n",
      "  0.8148782  -0.7642552  -0.32234916 -0.83504534 -0.48661792 -0.42191637\n",
      " -0.5468443  -0.08259413]\n"
     ]
    }
   ],
   "source": [
    "def mbkmeans_clusters(X, k, mb=500, print_silhouette_values=False):\n",
    "    \"\"\"Generate clusters.\n",
    "\n",
    "    Args:\n",
    "        X: Matrix of features.\n",
    "        k: Number of clusters.\n",
    "        mb: Size of mini-batches. Defaults to 500.\n",
    "        print_silhouette_values: Print silhouette values per cluster.\n",
    "\n",
    "    Returns:\n",
    "        Trained clustering model and labels based on X.\n",
    "    \"\"\"\n",
    "    km = MiniBatchKMeans(n_clusters=k, batch_size=mb).fit(X)\n",
    "    print(f\"For n_clusters = {k}\")\n",
    "    print(f\"Silhouette coefficient: {silhouette_score(X, km.labels_):0.2f}\")\n",
    "    print(f\"Inertia:{km.inertia_}\")\n",
    "\n",
    "    if print_silhouette_values:\n",
    "        sample_silhouette_values = silhouette_samples(X, km.labels_)\n",
    "        print(f\"Silhouette values:\")\n",
    "        silhouette_values = []\n",
    "        for i in range(k):\n",
    "            cluster_silhouette_values = sample_silhouette_values[km.labels_ == i]\n",
    "            silhouette_values.append(\n",
    "                (\n",
    "                    i,\n",
    "                    cluster_silhouette_values.shape[0],\n",
    "                    cluster_silhouette_values.mean(),\n",
    "                    cluster_silhouette_values.min(),\n",
    "                    cluster_silhouette_values.max(),\n",
    "                )\n",
    "            )\n",
    "        silhouette_values = sorted(\n",
    "            silhouette_values, key=lambda tup: tup[2], reverse=True\n",
    "        )\n",
    "        for s in silhouette_values:\n",
    "            print(\n",
    "                f\"    Cluster {s[0]}: Size:{s[1]} | Avg:{s[2]:.2f} | Min:{s[3]:.2f} | Max: {s[4]:.2f}\"\n",
    "            )\n",
    "    return km, km.labels_\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "outputs": [],
   "source": [
    "clustering, cluster_labels = mbkmeans_clusters(X=vectorized_docs, k=10, print_silhouette_values=True)\n",
    "\n",
    "df_clusters = pd.DataFrame({\n",
    "    \"text\": sentences,\n",
    "    \"tokens\": [\" \".join(text) for text in tokensSentenceslist],\n",
    "    \"cluster\": cluster_labels\n",
    "})"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Evaluate top terms of the cluster"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "print(\"Top terms per cluster (based on centroids):\")\n",
    "for i in range(10): # number of cluster k should be put here!!\n",
    "    tokens_per_cluster = \"\"\n",
    "    most_representative = model.wv.most_similar(positive=[clustering.cluster_centers_[i]], topn=3)\n",
    "    print(clustering.cluster_centers_[i][0])\n",
    "    for t in most_representative:\n",
    "        tokens_per_cluster += f\"{t[0]} \"\n",
    "    #print(f\"Cluster {i}: {tokens_per_cluster}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 145,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top terms per cluster (based on centroids):\n",
      "[ 1.19385659 -0.82888172  1.58800147  0.10622866 -0.04769936  0.53634079\n",
      "  1.2926703  -0.58823001  0.37684249 -0.0375403   1.1391392  -0.21388091\n",
      " -0.8419543  -0.18153256  0.01115879  0.0577653  -0.66395227  0.1070669\n",
      "  0.3855902   0.07921372  0.25195381 -0.24987248  0.91514523  0.87854672\n",
      " -0.2781197  -1.14427267  0.05927777  0.0140876  -1.56937785  0.24000135\n",
      "  0.75462581 -0.68548434 -0.51476748  0.84428861 -0.97498851  0.26553429\n",
      "  0.41518204 -0.35250388 -1.04682077  0.19067908 -0.42692063  0.4745817\n",
      "  0.7416655  -0.27141488  0.15662372 -0.24953608  0.13406592  0.3687836\n",
      " -0.95627766  0.222207  ]\n",
      "[ 0.70034438 -0.29410066  0.99018799  0.20499822 -0.04243745  0.39972958\n",
      "  0.64275578 -0.33103261 -0.0416056  -0.13465635  0.72499667  0.00946553\n",
      " -0.46231743  0.12923565 -0.10479293 -0.02107713 -0.41081607 -0.20373062\n",
      "  0.31501559 -0.29613619  0.14241664 -0.22131774  0.29306809  0.58699511\n",
      "  0.02967619 -0.48050582  0.10401114  0.04557529 -1.1784371   0.21390013\n",
      "  0.45816505 -0.42654698 -0.42213327  0.23249377 -0.60067039 -0.00714601\n",
      "  0.06972742 -0.79242107 -0.32436566  0.31826471 -0.1903578   0.1888943\n",
      "  0.86861939 -0.07438913  0.00163146 -0.15929379  0.02261223  0.21485612\n",
      " -0.57459968 -0.08225413]\n",
      "[ 0.87680405  0.17769165 -0.06149382  0.10299494  0.21017745  0.38209173\n",
      "  0.66265316  0.03091055  0.08586377 -0.04961441  0.07367984  0.04637753\n",
      " -0.3364137   0.23556231  0.09801026  0.3410713  -0.33291734  0.46806827\n",
      "  0.56448401 -0.5281131   0.5040896  -0.48118904  0.8111509  -0.14780404\n",
      " -0.09267816 -0.66997189  0.24608964 -0.50303203 -0.79106131  0.51385704\n",
      "  0.16467694  0.29749151 -0.49938007  0.63981882 -1.21195506 -0.47856271\n",
      " -0.12154764 -0.63650021 -0.46953281  0.27908484  0.13773129 -0.44739879\n",
      "  0.73058978 -0.49077334 -0.61268438 -0.85654807  0.20647105  0.60050473\n",
      " -0.56216424  0.23793198]\n",
      "[-0.76844432 -1.25434848 -0.89817861 -0.4872649  -0.51174063 -0.72061496\n",
      " -1.24559929  1.17013796 -1.21091203  0.43806427 -3.136237    0.63153871\n",
      "  0.82086549  0.93091113  0.92053555  0.17438994  0.66933869 -1.92182553\n",
      " -1.40150304  0.88426581 -0.57543769  1.2165533  -0.03329479 -0.20943162\n",
      "  1.08044635 -0.06718248 -1.73916592  0.1352895   0.2537576  -1.69712476\n",
      " -1.0954704  -0.58285535  0.43185717 -0.27600702  0.73456132 -0.26018284\n",
      "  0.26639602 -2.07585853 -0.07781209  0.37752775 -0.10678269  1.10467615\n",
      "  1.42708224 -1.80037385  1.28201314 -0.89088326  0.25478092  1.05220623\n",
      "  2.42349904 -1.21595062]\n",
      "[ 0.72495709  0.14475979  0.40799764  0.27970063  0.2102936   0.275352\n",
      "  0.72461644 -0.16936523 -0.19879436 -0.2411809   0.70835163 -0.01461002\n",
      " -0.53636936  0.4026937  -0.28224234 -0.02006721 -0.50878279  0.07689739\n",
      "  0.46378586 -0.53857228  0.23905007 -0.27670408  0.59705694  0.23643145\n",
      "  0.15449354 -0.30468422  0.30732507 -0.02902881 -0.91378765  0.61498539\n",
      "  0.26272278 -0.23255971 -0.3643824   0.12010869 -0.76939813  0.04313749\n",
      " -0.17627059 -0.954228   -0.00793967  0.26889068  0.03144133 -0.35512265\n",
      "  1.3081617   0.08485011 -0.41405977 -0.52281661  0.0487735   0.10062892\n",
      " -0.82999856  0.00857342]\n",
      "[ 0.1862343  -0.11928814  0.64157575  0.18916738 -0.06164319  0.47478056\n",
      "  0.47767201 -0.18430513 -0.33668927 -0.22272462  0.23875412 -0.06915736\n",
      " -0.23535693  0.29813641  0.02456747  0.14366317 -0.279819   -0.29810535\n",
      "  0.40442709 -0.06078638 -0.10547512 -0.28741835  0.13661381  0.54007948\n",
      "  0.13600225 -0.42526897  0.21995522  0.06299158 -1.04646038  0.14730518\n",
      "  0.11352069 -0.24965977 -0.25518571  0.18733943 -0.47796998 -0.38788114\n",
      "  0.10482437 -0.65152299 -0.34698002  0.19844831  0.21128888 -0.21353695\n",
      "  0.88448856 -0.14694666 -0.27908491 -0.21768364  0.1904046   0.44926837\n",
      " -0.21636985 -0.19828246]\n",
      "[ 1.05550857 -0.27926652  0.98400598  0.08045572 -0.05270257  0.41348022\n",
      "  1.01086682 -0.37046194  0.07002196 -0.15861953  0.81261122 -0.09323271\n",
      " -0.76286181  0.16544116 -0.26127282  0.03361953 -0.6959076   0.17517962\n",
      "  0.48729948 -0.34830074  0.22367952 -0.25308473  0.84309748  0.40807068\n",
      " -0.1203797  -0.68781496  0.23007076 -0.06614775 -1.16505112  0.51602947\n",
      "  0.5325158  -0.46409493 -0.39054003  0.69429896 -0.88099836  0.05661839\n",
      "  0.01793963 -0.60253454 -0.51368322  0.23450647 -0.15243675 -0.00393843\n",
      "  0.91365248 -0.12235944 -0.24606708 -0.4594543  -0.02486733  0.27603408\n",
      " -1.02090076  0.18005401]\n",
      "[ 0.53154852  0.05822137  0.71695471 -0.09933173 -0.15213348  0.54945457\n",
      "  0.46212665 -0.09626168 -0.45852293  0.27409792  0.54554463  0.05781892\n",
      " -0.49956725 -0.09202479 -0.37892304 -0.77950287 -0.7555575  -0.09641011\n",
      "  0.32549681 -0.58387138  0.04535827 -0.27303458  0.33067667  0.54262813\n",
      " -0.26110005 -0.32205161  0.25482536 -0.21251364 -0.97184962  0.35363962\n",
      "  0.50528119 -0.36173027 -0.18802746  0.51400772 -0.58325209  0.16214805\n",
      "  0.04007741 -0.99699542  0.20381069  0.62732208 -0.17845907 -0.22152632\n",
      "  0.97577877  0.15832591 -0.22842396 -0.613457   -0.039155    0.20379021\n",
      " -0.25717802  0.12913693]\n",
      "[ 1.47608547e+00  6.16046426e-01 -6.64859964e-02  1.98194706e-02\n",
      "  1.90799499e-01  3.59283688e-02  9.38693759e-01  3.04836202e-02\n",
      " -4.05776165e-01 -3.29153196e-01  4.53885476e-01  2.33298877e-01\n",
      " -6.51445220e-01  5.74452951e-01 -5.75660094e-01 -7.75072161e-02\n",
      " -7.46323367e-01  9.62636480e-01  1.51235484e-01 -1.17508608e+00\n",
      "  8.80390472e-01  2.49045011e-01  1.47801163e+00 -7.88344344e-01\n",
      "  1.14371974e-03 -1.66303088e-01  1.61641463e-01 -1.61624573e-01\n",
      " -1.30788483e-01  7.84475515e-01  1.43908924e-01 -1.91293917e-01\n",
      " -8.18643529e-01  4.01192031e-01 -8.62952997e-01  4.79156167e-01\n",
      " -5.76226448e-01 -1.15930233e+00  3.55280306e-01 -2.42530886e-01\n",
      " -1.21595208e-01 -9.39705379e-01  1.33975134e+00 -2.95041531e-01\n",
      " -6.31825521e-01 -1.42370130e+00 -2.83156721e-01  2.85868340e-01\n",
      " -1.20384908e+00  4.29519704e-01]\n",
      "[ 0.65911129 -0.56532524  1.18898244  0.0909282  -0.18695495  0.83740123\n",
      "  0.90987382 -0.3578946  -0.0434072  -0.07577782  0.47337072 -0.11474554\n",
      " -0.40097285 -0.23743761  0.03351181 -0.01151638 -0.68860301 -0.08781029\n",
      "  0.52730607  0.09174726  0.13695406 -0.3738483   0.50086644  0.61459489\n",
      " -0.36579022 -0.89880208  0.2247167  -0.0375501  -1.37450747  0.1585492\n",
      "  0.57605422 -0.6207138  -0.3395134   0.6049483  -0.63571466 -0.15792889\n",
      "  0.31636853 -0.29490854 -0.59421177  0.16201423  0.05088653  0.15823958\n",
      "  0.70944428 -0.38412971 -0.02564572 -0.1435398   0.12045884  0.60281539\n",
      " -0.57773778 -0.05969448]\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Retrieve a random sample of documents for a given cluster\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the parents have the ability and not only that they must protect their children from these influenses\n",
      "-------------\n",
      "businsesses need the television advertising to improve the children to buy the toys\n",
      "-------------\n",
      "they cant play with their kids\n",
      "-------------\n",
      "we might not want to buy the product but we do remember the brand\n",
      "-------------\n",
      "and also when children have their toys they dont annoy the parents if theyre bored\n",
      "-------------\n",
      "it is simmilar to money if you guard your child from all the money they can not handle it when they are adult but when you give them pocket money and learn them how to handle it they will get use to it\n",
      "-------------\n",
      "children think that they are like them\n",
      "-------------\n",
      "for children thats a reality they maybe dont have but they want it to be like that\n",
      "-------------\n",
      "but this argument can also turned into an argument thats against this statement because the children could learn that they cant always have what they want if the parents persist and dont buy them the toys\n",
      "-------------\n",
      "they should do that because they decide about the future of the children and what he or she will be like\n",
      "-------------\n"
     ]
    }
   ],
   "source": [
    "for i,t in enumerate(df_clusters.query(f\"cluster == {0}\").sample(10).iterrows()):\n",
    "    print(t[1][\"text\"])\n",
    "    print(\"-------------\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "outputs": [
    {
     "data": {
      "text/plain": "(38715, 3)"
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clusters.shape\n",
    "\n",
    "# df_clusters.tokens[0]\n",
    "# df_clusters.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Most representative clusters"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "if the parents know things better and its up to hope they do they will be the bad guys because they want whitout any measuring reason their kids to not get these toys\n",
      "-------------\n",
      "while it can help some people figure out what their children would like to have it usually just leaves the child wanting something that they usually dont get because they cant have every toy they see on tv or because the parents are just not able to afford it\n",
      "-------------\n",
      "parents need to tell their children that they should not be greedy and have joy with the things they havethe child will probably understand it and just move on\n",
      "-------------\n",
      "the second problem could be that poor parents cant buy their children the toys which they see in the television and then the parents can begin to feel bad and the children thinks their parents dont like them because in this age they often dont understand what poorness is\n",
      "-------------\n",
      "parents should also try to teach their children that they cant get anything they see on the television just because it is advertised\n",
      "-------------\n",
      "small children might see something that they like in the ads and force their parents to buy something totally unnecessary\n",
      "-------------\n",
      "if they see something that looks cool on television they will probably desire it which could cause stress for their parents since they might not be able to afford it or just simply dont want to spoil their kids\n",
      "-------------\n",
      "for it speaks that many children want to have everything they watch in the television advertising and many parents cannot afford every wish they have because for example they do not have enough money to buy the toys\n",
      "-------------\n",
      "the advertisings are often doing it on purpose to impress children so that they want to have the product and are annoying their parents until they get it\n",
      "-------------\n",
      "so it is clever to let the kids see what is new and what they could buy because if only the parents would see it they  think its just an other dumb ad but if their kid begs them to buy it they are letting themselves easier to buy it because they dont want to be cruel\n",
      "-------------\n"
     ]
    }
   ],
   "source": [
    "test_cluster = 0\n",
    "most_representative_docs = np.argsort(\n",
    "    np.linalg.norm(vectorized_docs - clustering.cluster_centers_[test_cluster], axis=1)\n",
    ")\n",
    "for d in most_representative_docs[:10]:\n",
    "    print(sentences[d])\n",
    "    print(\"-------------\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}