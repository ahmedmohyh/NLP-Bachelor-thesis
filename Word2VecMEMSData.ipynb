{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Importing section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "outputs": [],
   "source": [
    "import os\n",
    "import string\n",
    "from nltk import tokenize\n",
    "from gensim.models import Word2Vec\n",
    "from nltk import word_tokenize\n",
    "import numpy as np\n",
    "from sklearn.cluster import MiniBatchKMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.metrics import silhouette_samples\n",
    "import pandas as pd"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Reading the data from the folder and cleaning it."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "outputs": [],
   "source": [
    "sentences = []\n",
    "for filename in os.listdir(r\"D:\\UDE\\6th Semester\\MEMS\\MEWS Data\\MEWS_Essays\\MEWS_Essays\\Essays_all\\TelevisonMergedT1+T2\"):\n",
    "   with open(os.path.join(r\"D:\\UDE\\6th Semester\\MEMS\\MEWS Data\\MEWS_Essays\\MEWS_Essays\\Essays_all\\TelevisonMergedT1+T2\", filename)) as f:\n",
    "       text = f.read()\n",
    "       text = text.replace(\"ï»¿\",\"\")\n",
    "       sents = tokenize.sent_tokenize(text)\n",
    "       for s in sents:\n",
    "           s = s.lower()\n",
    "           s = s.translate(str.maketrans('', '', string.punctuation))\n",
    "           sentences.append(s)\n",
    "\n",
    "tokensSentenceslist = []\n",
    "\n",
    "for s  in sentences:\n",
    "    wordsList = word_tokenize(s)\n",
    "    tokensSentenceslist.append(wordsList)\n",
    "\n",
    "\n",
    "##################### Uncomment below section for testing #########################\n",
    "# print(len(sentences))\n",
    "#\n",
    "# for s in sentences:\n",
    "#      print(\"The sentence is : \")\n",
    "#      print(s)\n",
    "#      print(\"-----------------------End of the sentence -------------\")\n",
    "#\n",
    "# print (sentences)\n",
    "\n",
    "\n",
    "# print (len(tokensSentenceslist))\n",
    "# print (tokensSentenceslist)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38715\n",
      "['advertising in television is becoming more and more clever', 'lots of those ads invade our subconsciousness and try to make us buy the product even if we do not actually need it', 'when it comes to children lots of them dont have enough money to afford these products', 'they dont even understand the concept of money', 'even if they wanted it they can not get the thing they were told they need']\n"
     ]
    }
   ],
   "source": [
    "print (len(sentences))\n",
    "print(sentences[0:5])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Generating the Word2Vec Model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "outputs": [
    {
     "data": {
      "text/plain": "(2373525, 3636460)"
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#model = Word2Vec(tokensSentenceslist, min_count=1)\n",
    "\n",
    "#model = Word2Vec(tokensSentenceslist, vector_size=50, min_count=1, sg=1)\n",
    "#model = Word2Vec(sentences=tokensSentenceslist, vector_size=100, workers=1, seed=42)\n",
    "\n",
    "model = Word2Vec(window=10, min_count=2,workers=6,vector_size=50,seed=42,sg=0)\n",
    "model.build_vocab(tokensSentenceslist, progress_per=1000)\n",
    "model.train(tokensSentenceslist, total_examples=model.corpus_count, epochs=model.epochs)\n",
    "\n",
    "\n",
    "##################### Uncomment below section for testing #########################\n",
    "\n",
    "\n",
    "# print(list(model.wv.index_to_key))\n",
    "# print(len(list(model.wv.index_to_key)))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "outputs": [
    {
     "data": {
      "text/plain": "38715"
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.corpus_count\n",
    "#model.epochs"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "outputs": [
    {
     "data": {
      "text/plain": "[('televison', 0.936676561832428),\n ('tv', 0.8420758843421936),\n ('televsion', 0.5288699269294739),\n ('sholdnt', 0.49897295236587524),\n ('telvesion', 0.4982863664627075),\n ('certanly', 0.47414037585258484),\n ('frog', 0.4550800025463104),\n ('needless', 0.439322292804718),\n ('televion', 0.43875852227211),\n ('excemple', 0.43604832887649536)]"
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar(\"television\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "outputs": [
    {
     "data": {
      "text/plain": "[('televison', 0.936676561832428),\n ('tv', 0.8420758843421936),\n ('televsion', 0.5288699269294739),\n ('sholdnt', 0.49897295236587524),\n ('telvesion', 0.4982863664627075),\n ('certanly', 0.47414037585258484),\n ('frog', 0.4550800025463104),\n ('needless', 0.439322292804718),\n ('televion', 0.43875852227211),\n ('excemple', 0.43604832887649536)]"
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar(\"television\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "outputs": [
    {
     "data": {
      "text/plain": "[('aspect', 0.8733988404273987),\n ('point', 0.8479516506195068),\n ('reason', 0.794777512550354),\n ('arguments', 0.7330032587051392),\n ('pro', 0.7329370379447937),\n ('topic', 0.7114583849906921),\n ('fact', 0.7027332782745361),\n ('positiv', 0.6803781390190125),\n ('theme', 0.6697933077812195),\n ('against', 0.6697912216186523)]"
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar(\"argument\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "outputs": [
    {
     "data": {
      "text/plain": "[('aspect', 0.8631858229637146),\n ('point', 0.8416258692741394),\n ('reason', 0.8248558640480042),\n ('statement', 0.6963896155357361),\n ('fact', 0.6947038173675537),\n ('topic', 0.6936120390892029),\n ('against', 0.6935745477676392),\n ('pro', 0.6923171281814575),\n ('arguement', 0.6699721813201904),\n ('arguments', 0.6554367542266846)]"
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar(\"argument\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "outputs": [
    {
     "data": {
      "text/plain": "-0.1692446"
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.similarity(\"tv\",\"against\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "outputs": [],
   "source": [
    "def vectorize(list_of_docs, model, strategy):\n",
    "    \"\"\"Generate vectors for list of documents using a Word Emx`bedding.\n",
    "\n",
    "    Args:\n",
    "        list_of_docs: List of documents.\n",
    "        model: Gensim Word Embedding.\n",
    "        strategy: Aggregation strategy (\"average\", or \"min-max\".)\n",
    "\n",
    "    Raises:\n",
    "        ValueError: If the strategy is other than \"average\" or \"min-max\".\n",
    "\n",
    "    Returns:\n",
    "        List of vectors.\n",
    "    \"\"\"\n",
    "    features = []\n",
    "    size_output = model.vector_size\n",
    "    embedding_dict = model\n",
    "\n",
    "    if strategy == \"min-max\":\n",
    "        size_output *= 2\n",
    "\n",
    "    if hasattr(model, \"wv\"):\n",
    "        embedding_dict = model.wv\n",
    "\n",
    "    for tokens in list_of_docs:\n",
    "        zero_vector = np.zeros(size_output)\n",
    "        vectors = []\n",
    "        for token in tokens:\n",
    "            if token in embedding_dict:\n",
    "                try:\n",
    "                    vectors.append(embedding_dict[token])\n",
    "                except KeyError:\n",
    "                    continue\n",
    "        if vectors:\n",
    "            vectors = np.asarray(vectors)\n",
    "            if strategy == \"min-max\":\n",
    "                min_vec = vectors.min(axis=0)\n",
    "                max_vec = vectors.max(axis=0)\n",
    "                features.append(np.concatenate((min_vec, max_vec)))\n",
    "            elif strategy == \"average\":\n",
    "                avg_vec = vectors.mean(axis=0)\n",
    "                features.append(avg_vec)\n",
    "            else:\n",
    "                raise ValueError(f\"Aggregation strategy {strategy} does not exist!\")\n",
    "        else:\n",
    "            features.append(zero_vector)\n",
    "    return features"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "outputs": [
    {
     "data": {
      "text/plain": "(38715, 50)"
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorized_docs = vectorize(tokensSentenceslist, model=model, strategy=\"average\")\n",
    "len(vectorized_docs), len(vectorized_docs[0])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.0834987   1.0775832  -2.4190793   1.3539352   0.7693121  -0.01766455\n",
      " -0.53748876  2.1623745  -0.5207145   1.694928   -0.2794287   1.4977117\n",
      "  0.3757558  -1.0392004  -1.1415775  -0.37531468  0.23239893  1.364053\n",
      "  1.6795251   0.6714833   0.8824193   1.365521    1.8032991  -0.67293257\n",
      "  1.0104337  -0.03604451  1.0017824  -0.5705173  -0.49769476  1.6430551\n",
      " -1.352539    1.2772088   0.03308525 -2.0387952  -2.4316406  -1.2589905\n",
      "  0.95908076 -2.2138608   0.6789476  -1.0684443   0.03440151  0.9796872\n",
      "  0.9881222  -1.3170159  -2.6712847  -1.2676587   1.5911027  -0.6523292\n",
      " -1.2096913   0.46780825]\n",
      "#######################################################\n",
      "[ 0.09301123  0.02892222  0.02476533  0.29560983 -0.7727718   0.23872662\n",
      "  0.4515218  -0.06879666 -0.03741706 -0.3008877  -0.20542604  0.8528051\n",
      " -0.14720449 -0.2436079  -1.0440915  -0.17934558 -0.21951494 -0.6070896\n",
      "  0.41599515  0.6486483  -0.45739534  0.38212645  0.3662845   0.4625144\n",
      "  0.98150975 -0.35466102  0.38813674 -0.44521755 -1.4364208  -0.07891957\n",
      " -0.056222   -0.19564575  0.38996303 -0.32186234  0.00216475  1.0545774\n",
      " -0.41077358 -0.5827029  -0.9488093   0.06095479 -0.050621   -0.20328291\n",
      "  0.8148782  -0.7642552  -0.32234916 -0.83504534 -0.48661792 -0.42191637\n",
      " -0.5468443  -0.08259413]\n"
     ]
    }
   ],
   "source": [
    "print(model.wv[\"argument\"])\n",
    "print(\"#######################################################\")\n",
    "print(vectorized_docs[0])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "outputs": [],
   "source": [
    "def mbkmeans_clusters(X, k, mb=500, print_silhouette_values=False):\n",
    "    \"\"\"Generate clusters.\n",
    "\n",
    "    Args:\n",
    "        X: Matrix of features.\n",
    "        k: Number of clusters.\n",
    "        mb: Size of mini-batches. Defaults to 500.\n",
    "        print_silhouette_values: Print silhouette values per cluster.\n",
    "\n",
    "    Returns:\n",
    "        Trained clustering model and labels based on X.\n",
    "    \"\"\"\n",
    "    km = MiniBatchKMeans(n_clusters=k, batch_size=mb).fit(X)\n",
    "    print(f\"For n_clusters = {k}\")\n",
    "    print(f\"Silhouette coefficient: {silhouette_score(X, km.labels_):0.2f}\")\n",
    "    print(f\"Inertia:{km.inertia_}\")\n",
    "\n",
    "    if print_silhouette_values:\n",
    "        sample_silhouette_values = silhouette_samples(X, km.labels_)\n",
    "        print(f\"Silhouette values:\")\n",
    "        silhouette_values = []\n",
    "        for i in range(k):\n",
    "            cluster_silhouette_values = sample_silhouette_values[km.labels_ == i]\n",
    "            silhouette_values.append(\n",
    "                (\n",
    "                    i,\n",
    "                    cluster_silhouette_values.shape[0],\n",
    "                    cluster_silhouette_values.mean(),\n",
    "                    cluster_silhouette_values.min(),\n",
    "                    cluster_silhouette_values.max(),\n",
    "                )\n",
    "            )\n",
    "        silhouette_values = sorted(\n",
    "            silhouette_values, key=lambda tup: tup[2], reverse=True\n",
    "        )\n",
    "        for s in silhouette_values:\n",
    "            print(\n",
    "                f\"    Cluster {s[0]}: Size:{s[1]} | Avg:{s[2]:.2f} | Min:{s[3]:.2f} | Max: {s[4]:.2f}\"\n",
    "            )\n",
    "    return km, km.labels_\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For n_clusters = 10\n",
      "Silhouette coefficient: 0.07\n",
      "Inertia:219602.97053755476\n",
      "Silhouette values:\n",
      "    Cluster 3: Size:662 | Avg:0.67 | Min:0.04 | Max: 0.74\n",
      "    Cluster 8: Size:2596 | Avg:0.15 | Min:-0.09 | Max: 0.37\n",
      "    Cluster 1: Size:6052 | Avg:0.10 | Min:0.02 | Max: 0.25\n",
      "    Cluster 0: Size:3614 | Avg:0.09 | Min:-0.05 | Max: 0.29\n",
      "    Cluster 6: Size:5933 | Avg:0.04 | Min:-0.06 | Max: 0.19\n",
      "    Cluster 4: Size:5220 | Avg:0.04 | Min:-0.09 | Max: 0.23\n",
      "    Cluster 9: Size:4678 | Avg:0.04 | Min:-0.08 | Max: 0.22\n",
      "    Cluster 5: Size:5180 | Avg:0.03 | Min:-0.10 | Max: 0.21\n",
      "    Cluster 7: Size:2625 | Avg:0.02 | Min:-0.11 | Max: 0.22\n",
      "    Cluster 2: Size:2155 | Avg:-0.01 | Min:-0.21 | Max: 0.23\n"
     ]
    }
   ],
   "source": [
    "clustering, cluster_labels = mbkmeans_clusters(X=vectorized_docs, k=10, print_silhouette_values=True)\n",
    "df_clusters = pd.DataFrame({\n",
    "    \"text\": sentences,\n",
    "    \"tokens\": [\" \".join(text) for text in tokensSentenceslist],\n",
    "    \"cluster\": cluster_labels\n",
    "})"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Evaluate top terms of the cluster"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top terms per cluster (based on centroids):\n",
      "Cluster 0: they want parents \n",
      "Cluster 1: actually also the \n",
      "Cluster 2: summarizing i but \n",
      "Cluster 3: haben minuten dafã¼r \n",
      "Cluster 4: also bad that \n",
      "Cluster 5: just sayed adverisement \n",
      "Cluster 6: they that really \n",
      "Cluster 7: also advertises programms \n",
      "Cluster 8: allowed diricted young \n",
      "Cluster 9: they just maybe \n"
     ]
    }
   ],
   "source": [
    "print(\"Top terms per cluster (based on centroids):\")\n",
    "for i in range(10): # number of cluster k should be put here!!\n",
    "    tokens_per_cluster = \"\"\n",
    "    most_representative = model.wv.most_similar(positive=[clustering.cluster_centers_[i]], topn=3)\n",
    "    for t in most_representative:\n",
    "        tokens_per_cluster += f\"{t[0]} \"\n",
    "    print(f\"Cluster {i}: {tokens_per_cluster}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Retrieve a random sample of documents for a given cluster\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "and they will learn that you dont need the latest toy to have fun and be happy\n",
      "-------------\n",
      "what the boy then does is to ask the parents if he could have this toy\n",
      "-------------\n",
      "some parents let their children watch televison because they are noises by their kids and when they need silence they let them watsch on the tv\n",
      "-------------\n",
      "the children learn that they cant have everything they see\n",
      "-------------\n",
      "a good thing about tv advertising directed toward children is that parents get new ideas what they could buy their children as a present if they ask for\n",
      "-------------\n",
      "another argument is that the children in most cases cant buy the products anyway because they dont have any money so they have to ask their parents if they can get the product or not and if the parents say no the children maybe learns that it cant always have everything it wants to have\n",
      "-------------\n",
      "if companies didnt do that children would not have as much fun as they are having because they dont get the kind of toys they like\n",
      "-------------\n",
      "they don not want to buy this products but can not say something against they childrens\n",
      "-------------\n",
      "for children thats a reality they maybe dont have but they want it to be like that\n",
      "-------------\n",
      "we all know how childrens behave when they really really want something\n",
      "-------------\n"
     ]
    }
   ],
   "source": [
    "for i,t in enumerate(df_clusters.query(f\"cluster == {0}\").sample(10).iterrows()):\n",
    "    print(t[1][\"text\"])\n",
    "    print(\"-------------\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "outputs": [
    {
     "data": {
      "text/plain": "'advertising in television is becoming more and more clever'"
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clusters.shape\n",
    "\n",
    "df_clusters.tokens[0]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Most representative clusters"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "those people do not want their children to see this role model for society because it is not quiet reality but when you think of the stories the generations before had been listening every eveing in the bed those stories have not been quiet realistic and it might be good this way to give your children the immage of a better world a better future than we live in today and that is why those movies and tv shows for kids show us a different world that wants to encourage children to use their creativity and immagination but these movies have to be worth their production costs so that they have to show commercial\n",
      "-------------\n",
      "rich companis can do a lot of it and get more costumers so they get even richer while poor companis can just do a little and will only reach a few people and wont get a lot of money so they stay poor and often get bought by a rich company so that in the end we only heve one or two very rich companis who dominate the market and no other company can rise because the rich ones can lower the price without lossing much while the small one cant exist at the low pricebecause especially children dont kniw what other companis exist and when the see a advertisement for product x from company y they just want product x from company y and not from company p\n",
      "so all in all the advertisement to children makes them wanting things they do not need and makes them spend more time onscreen while the big companis get even bigger and bring small companis to give up\n",
      "-------------\n"
     ]
    }
   ],
   "source": [
    "test_cluster = 1\n",
    "most_representative_docs = np.argsort(\n",
    "    np.linalg.norm(vectorized_docs - clustering.cluster_centers_[test_cluster], axis=1)\n",
    ")\n",
    "for d in most_representative_docs[:2]:\n",
    "    print(sentences[d])\n",
    "    print(\"-------------\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}